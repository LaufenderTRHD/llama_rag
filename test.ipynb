{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=\"meta-llama/Llama-3.2-1B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-1B\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-3.2-1B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# huggingface-cli download meta-llama/Llama-3.2-1B  --local-dir D:\\LLama3\\model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pathlib in c:\\users\\doein\\anaconda3\\lib\\site-packages (1.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\doein\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Error parsing dependencies of pyodbc: Invalid version: '4.0.0-unsupported'\n",
      "WARNING: Error parsing dependencies of pyzmq: Invalid version: 'cpython'\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\doein\\anaconda3\\lib\\site-packages)\n",
      "ERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\doein\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 105, in _run_wrapper\n",
      "    status = _inner_run()\n",
      "  File \"c:\\Users\\doein\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 96, in _inner_run\n",
      "    return self.run(options, args)\n",
      "  File \"c:\\Users\\doein\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\req_command.py\", line 67, in wrapper\n",
      "    return func(self, options, args)\n",
      "  File \"c:\\Users\\doein\\anaconda3\\lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 483, in run\n",
      "    installed_versions[distribution.canonical_name] = distribution.version\n",
      "  File \"c:\\Users\\doein\\anaconda3\\lib\\site-packages\\pip\\_internal\\metadata\\pkg_resources.py\", line 192, in version\n",
      "    return parse_version(self._dist.version)\n",
      "  File \"c:\\Users\\doein\\anaconda3\\lib\\site-packages\\pip\\_vendor\\packaging\\version.py\", line 56, in parse\n",
      "    return Version(version)\n",
      "  File \"c:\\Users\\doein\\anaconda3\\lib\\site-packages\\pip\\_vendor\\packaging\\version.py\", line 202, in __init__\n",
      "    raise InvalidVersion(f\"Invalid version: '{version}'\")\n",
      "pip._vendor.packaging.version.InvalidVersion: Invalid version: '4.0.0-unsupported'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ruamel-yaml in c:\\users\\doein\\anaconda3\\lib\\site-packages (0.18.6)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in c:\\users\\doein\\anaconda3\\lib\\site-packages (from ruamel-yaml) (0.2.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\doein\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Error parsing dependencies of pyodbc: Invalid version: '4.0.0-unsupported'\n",
      "WARNING: Error parsing dependencies of pyzmq: Invalid version: 'cpython'\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\doein\\anaconda3\\lib\\site-packages)\n",
      "ERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\doein\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 105, in _run_wrapper\n",
      "    status = _inner_run()\n",
      "  File \"c:\\Users\\doein\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 96, in _inner_run\n",
      "    return self.run(options, args)\n",
      "  File \"c:\\Users\\doein\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\req_command.py\", line 67, in wrapper\n",
      "    return func(self, options, args)\n",
      "  File \"c:\\Users\\doein\\anaconda3\\lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 483, in run\n",
      "    installed_versions[distribution.canonical_name] = distribution.version\n",
      "  File \"c:\\Users\\doein\\anaconda3\\lib\\site-packages\\pip\\_internal\\metadata\\pkg_resources.py\", line 192, in version\n",
      "    return parse_version(self._dist.version)\n",
      "  File \"c:\\Users\\doein\\anaconda3\\lib\\site-packages\\pip\\_vendor\\packaging\\version.py\", line 56, in parse\n",
      "    return Version(version)\n",
      "  File \"c:\\Users\\doein\\anaconda3\\lib\\site-packages\\pip\\_vendor\\packaging\\version.py\", line 202, in __init__\n",
      "    raise InvalidVersion(f\"Invalid version: '{version}'\")\n",
      "pip._vendor.packaging.version.InvalidVersion: Invalid version: '4.0.0-unsupported'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\doein\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\doein\\anaconda3\\lib\\site-packages (from torch) (3.0.12)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\doein\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\doein\\anaconda3\\lib\\site-packages (from torch) (1.8)\n",
      "Requirement already satisfied: networkx in c:\\users\\doein\\anaconda3\\lib\\site-packages (from torch) (3.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\doein\\anaconda3\\lib\\site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\doein\\anaconda3\\lib\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\doein\\anaconda3\\lib\\site-packages (from jinja2->torch) (1.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\doein\\anaconda3\\lib\\site-packages (from sympy->torch) (1.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\doein\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Error parsing dependencies of pyodbc: Invalid version: '4.0.0-unsupported'\n",
      "WARNING: Error parsing dependencies of pyzmq: Invalid version: 'cpython'\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\doein\\anaconda3\\lib\\site-packages)\n",
      "ERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\doein\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 105, in _run_wrapper\n",
      "    status = _inner_run()\n",
      "  File \"c:\\Users\\doein\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 96, in _inner_run\n",
      "    return self.run(options, args)\n",
      "  File \"c:\\Users\\doein\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\req_command.py\", line 67, in wrapper\n",
      "    return func(self, options, args)\n",
      "  File \"c:\\Users\\doein\\anaconda3\\lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 483, in run\n",
      "    installed_versions[distribution.canonical_name] = distribution.version\n",
      "  File \"c:\\Users\\doein\\anaconda3\\lib\\site-packages\\pip\\_internal\\metadata\\pkg_resources.py\", line 192, in version\n",
      "    return parse_version(self._dist.version)\n",
      "  File \"c:\\Users\\doein\\anaconda3\\lib\\site-packages\\pip\\_vendor\\packaging\\version.py\", line 56, in parse\n",
      "    return Version(version)\n",
      "  File \"c:\\Users\\doein\\anaconda3\\lib\\site-packages\\pip\\_vendor\\packaging\\version.py\", line 202, in __init__\n",
      "    raise InvalidVersion(f\"Invalid version: '{version}'\")\n",
      "pip._vendor.packaging.version.InvalidVersion: Invalid version: '4.0.0-unsupported'\n"
     ]
    }
   ],
   "source": [
    "%pip install pathlib\n",
    "%pip install ruamel-yaml\n",
    "\n",
    "%pip install torch \n",
    "%pip install git+https://github.com/huggingface/transformers\n",
    "%pip install git+https://github.com/huggingface/accelerate\n",
    "%pip install huggingface_hub\n",
    "%pip install sentencepiece\n",
    "%pip install bitsandbytes\n",
    "\n",
    "%pip install haystack-ai duckduckgo-api-haystack transformers sentence-transformers datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install sentence-transformers \n",
    "#%pip install --upgrade transformers==3.1.0 --user\n",
    "#%pip install --upgrade tensorflow==2.2 --user\n",
    "#%pip install -U regex\n",
    "#%pip install -U --upgrade \"sentence-transformers>=3.0.0\" --user\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)\n",
    "import tensorflow\n",
    "print(tensorflow.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from haystack import Document\n",
    "\n",
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "from haystack.components.embedders import SentenceTransformersDocumentEmbedder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "document_store = InMemoryDocumentStore()\n",
    "\n",
    "dataset = load_dataset(\"bilgeyucel/seven-wonders\", split=\"train\")\n",
    "docs = [Document(content=doc[\"content\"], meta=doc[\"meta\"]) for doc in dataset]\n",
    "\n",
    "doc_embedder = SentenceTransformersDocumentEmbedder(model=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "doc_embedder.warm_up()\n",
    "\n",
    "docs_with_embeddings = doc_embedder.run(docs)\n",
    "document_store.write_documents(docs_with_embeddings[\"documents\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from haystack.components.generators import HuggingFaceLocalGenerator\n",
    "\n",
    "generator = HuggingFaceLocalGenerator(\n",
    "    model=\"meta-llama/Llama-3.2-1B\",\n",
    "    huggingface_pipeline_kwargs={\"device_map\":\"auto\",\n",
    "                                 \"torch_dtype\":torch.bfloat16},\n",
    "    generation_kwargs={\"max_new_tokens\": 256})\n",
    "\n",
    "generator.warm_up()\n",
    "\n",
    "prompt = \"\"\"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
    "  What is the capital of Australia?<|eot_id|>\n",
    "  <|start_header_id|>assistant<|end_header_id|>\"\"\"\n",
    "\n",
    "generator.run(prompt)\n",
    "\n",
    "from haystack.components.embedders import SentenceTransformersTextEmbedder\n",
    "from haystack.components.retrievers.in_memory import InMemoryEmbeddingRetriever\n",
    "\n",
    "text_embedder = SentenceTransformersTextEmbedder(model=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "retriever = InMemoryEmbeddingRetriever(document_store, top_k=5)\n",
    "\n",
    "from haystack.components.builders import PromptBuilder\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "Answer the following query given the documents.\n",
    "If the answer is not contained within the documents reply with 'no_answer'.\n",
    "If the answer is contained within the documents, start the answer with \"FROM THE KNOWLEDGE BASE: \".\n",
    "\n",
    "Documents:\n",
    "{% for document in documents %}\n",
    "  {{document.content}}\n",
    "{% endfor %}\n",
    "\n",
    "Query: {{query}}<|eot_id|>\n",
    "\n",
    "<|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\"\n",
    "\n",
    "prompt_builder = PromptBuilder(template=prompt_template)\n",
    "\n",
    "from haystack.components.routers import ConditionalRouter\n",
    "\n",
    "routes = [\n",
    "    {\n",
    "        \"condition\": \"{{'no_answer' in replies[0]}}\",\n",
    "        \"output\": \"{{query}}\",\n",
    "        \"output_name\": \"go_to_websearch\",\n",
    "        \"output_type\": str,\n",
    "    },\n",
    "    {\n",
    "        \"condition\": \"{{'no_answer' not in replies[0]}}\",\n",
    "        \"output\": \"{{replies[0]}}\",\n",
    "        \"output_name\": \"answer\",\n",
    "        \"output_type\": str,\n",
    "    },\n",
    "]\n",
    "\n",
    "router = ConditionalRouter(routes)\n",
    "\n",
    "from duckduckgo_api_haystack import DuckduckgoApiWebSearch\n",
    "\n",
    "websearch = DuckduckgoApiWebSearch(top_k=5)\n",
    "\n",
    "prompt_template_after_websearch = \"\"\"\n",
    "<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "Answer the following query given the documents retrieved from the web.\n",
    "Start the answer with \"FROM THE WEB: \".\n",
    "\n",
    "Documents:\n",
    "{% for document in documents %}\n",
    "  {{document.content}}\n",
    "{% endfor %}\n",
    "\n",
    "Query: {{query}}<|eot_id|>\n",
    "\n",
    "<|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\"\n",
    "\n",
    "prompt_builder_after_websearch = PromptBuilder(template=prompt_template_after_websearch)\n",
    "\n",
    "from haystack.components.joiners import BranchJoiner\n",
    "prompt_joiner  = BranchJoiner(str)\n",
    "\n",
    "from haystack import Pipeline\n",
    "\n",
    "pipe = Pipeline()\n",
    "pipe.add_component(\"text_embedder\", text_embedder)\n",
    "pipe.add_component(\"retriever\", retriever)\n",
    "pipe.add_component(\"prompt_builder\", prompt_builder)\n",
    "pipe.add_component(\"prompt_joiner\", prompt_joiner)\n",
    "pipe.add_component(\"llm\", generator)\n",
    "pipe.add_component(\"router\", router)\n",
    "pipe.add_component(\"websearch\", websearch)\n",
    "pipe.add_component(\"prompt_builder_after_websearch\", prompt_builder_after_websearch)\n",
    "\n",
    "pipe.connect(\"text_embedder\", \"retriever\")\n",
    "pipe.connect(\"retriever\", \"prompt_builder.documents\")\n",
    "pipe.connect(\"prompt_builder\", \"prompt_joiner\")\n",
    "pipe.connect(\"prompt_joiner\", \"llm\")\n",
    "pipe.connect(\"llm.replies\", \"router.replies\")\n",
    "pipe.connect(\"router.go_to_websearch\", \"websearch.query\")\n",
    "pipe.connect(\"router.go_to_websearch\", \"prompt_builder_after_websearch.query\")\n",
    "pipe.connect(\"websearch.documents\", \"prompt_builder_after_websearch.documents\")\n",
    "pipe.connect(\"prompt_builder_after_websearch\", \"prompt_joiner\")\n",
    "\n",
    "def get_answer(query):\n",
    "  result = pipe.run({\"text_embedder\": {\"text\": query}, \"prompt_builder\": {\"query\": query}, \"router\": {\"query\": query}})\n",
    "  print(result[\"router\"][\"answer\"])\n",
    "\n",
    "\n",
    "query = \"Why did people build Great Pyramid of Giza?\"\n",
    "\n",
    "get_answer(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
